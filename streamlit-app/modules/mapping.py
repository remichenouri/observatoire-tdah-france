"""
Module Cartographie - Observatoire TDAH
Visualisations g√©ographiques et analyses territoriales
"""

import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
import folium
from streamlit_folium import st_folium
import geopandas as gpd
from datetime import datetime
import json

def show_mapping():
    """Interface principale de cartographie"""
    
    st.markdown("# üó∫Ô∏è Cartographie TDAH France")
    st.markdown("Visualisations g√©ographiques et analyses territoriales")
    
    # Navigation par onglets
    tab1, tab2, tab3, tab4 = st.tabs([
        "üá´üá∑ Vue France", 
        "üìç Densit√© M√©dicale",
        "üìä Analyses R√©gionales", 
        "üîç Comparaisons"
    ])
    
    with tab1:
        show_france_overview()
    
    with tab2:
        show_medical_density_map()
        
    with tab3:
        show_regional_analysis()
        
    with tab4:
        show_regional_comparisons()

def show_france_overview():
    """Vue d'ensemble de la France"""
    
    st.markdown("### üá´üá∑ Pr√©valence TDAH par R√©gion")
    
    # S√©lecteurs
    col1, col2, col3 = st.columns(3)
    
    with col1:
        metric = st.selectbox(
            "M√©trique √† afficher",
            ["Pr√©valence (%)", "Cas Estim√©s", "Taux Diagnostic (%)", "Prescriptions/1000hab"]
        )
    
    with col2:
        year = st.selectbox("Ann√©e", [2024, 2023, 2022, 2021])
        
    with col3:
        age_group = st.selectbox("Groupe d'√¢ge", ["Tous", "6-11 ans", "12-17 ans", "18+ ans"])
    
    # G√©n√©ration des donn√©es g√©ographiques simul√©es
    regions_data = generate_regions_data(metric, year, age_group)
    
    # Carte interactive avec Folium
    create_france_choropleth_map(regions_data, metric)
    
    # Statistiques rapides
    show_geographic_stats(regions_data, metric)

def generate_regions_data(metric, year, age_group):
    """G√©n√©ration des donn√©es g√©ographiques simul√©es"""
    
    # Donn√©es des r√©gions fran√ßaises
    regions = {
        '√éle-de-France': {'lat': 48.8566, 'lon': 2.3522, 'code': '11'},
        'Centre-Val de Loire': {'lat': 47.7516, 'lon': 1.6751, 'code': '24'},
        'Bourgogne-Franche-Comt√©': {'lat': 47.2805, 'lon': 4.9950, 'code': '27'},
        'Normandie': {'lat': 49.1829, 'lon': -0.3707, 'code': '28'},
        'Hauts-de-France': {'lat': 49.6649, 'lon': 2.5282, 'code': '32'},
        'Grand Est': {'lat': 48.6921, 'lon': 6.1844, 'code': '44'},
        'Pays de la Loire': {'lat': 47.7633, 'lon': -0.3299, 'code': '52'},
        'Bretagne': {'lat': 48.2020, 'lon': -2.9326, 'code': '53'},
        'Nouvelle-Aquitaine': {'lat': 45.7640, 'lon': 0.8034, 'code': '75'},
        'Occitanie': {'lat': 43.8927, 'lon': 2.0435, 'code': '76'},
        'Auvergne-Rh√¥ne-Alpes': {'lat': 45.4472, 'lon': 4.3854, 'code': '84'},
        'Provence-Alpes-C√¥te d\'Azur': {'lat': 43.9352, 'lon': 6.0679, 'code': '93'},
        'Corse': {'lat': 42.0396, 'lon': 9.0129, 'code': '94'}
    }
    
    # Simulation des valeurs selon la m√©trique
    np.random.seed(42)
    
    data = []
    for region_name, region_info in regions.items():
        
        if metric == "Pr√©valence (%)":
            value = np.random.normal(5.9, 1.2)  # Moyenne 5.9%, √©cart-type 1.2%
            value = max(3.0, min(9.0, value))  # Borner entre 3% et 9%
            
        elif metric == "Cas Estim√©s":
            # Bas√© sur la population r√©gionale approximative
            pop_base = np.random.randint(500000, 12000000)
            value = int(pop_base * np.random.uniform(0.04, 0.08))  # 4-8% de la population
            
        elif metric == "Taux Diagnostic (%)":
            value = np.random.normal(58, 12)  # Moyenne 58%, √©cart-type 12%
            value = max(30, min(85, value))  # Borner entre 30% et 85%
            
        else:  # Prescriptions/1000hab
            value = np.random.normal(12.5, 3.2)  # Moyenne 12.5 pour 1000, √©cart-type 3.2
            value = max(5, min(25, value))  # Borner entre 5 et 25
        
        data.append({
            'Region': region_name,
            'Code': region_info['code'],
            'Latitude': region_info['lat'],
            'Longitude': region_info['lon'],
            'Value': round(value, 1),
            'Metric': metric
        })
    
    return pd.DataFrame(data)

def create_france_choropleth_map(regions_data, metric):
    """Cr√©ation de la carte choropl√®the de France"""
    
    # Cr√©ation de la carte Folium
    m = folium.Map(
        location=[46.6034, 1.8883],  # Centre de la France
        zoom_start=6,
        tiles='OpenStreetMap'
    )
    
    # D√©terminer la palette de couleurs selon la m√©trique
    if "Pr√©valence" in metric or "Taux" in metric:
        colormap = folium.LinearColormap(
            colors=['green', 'yellow', 'orange', 'red'],
            vmin=regions_data['Value'].min(),
            vmax=regions_data['Value'].max()
        )
    else:
        colormap = folium.LinearColormap(
            colors=['lightblue', 'blue', 'darkblue'],
            vmin=regions_data['Value'].min(),
            vmax=regions_data['Value'].max()
        )
    
    # Ajouter les marqueurs pour chaque r√©gion
    for _, row in regions_data.iterrows():
        
        # Couleur selon la valeur
        color = colormap(row['Value'])
        
        # Taille du marqueur selon la valeur (normalis√©e)
        min_val, max_val = regions_data['Value'].min(), regions_data['Value'].max()
        normalized_size = 10 + 30 * (row['Value'] - min_val) / (max_val - min_val)
        
        # Popup avec informations d√©taill√©es
        popup_text = f"""
        <b>{row['Region']}</b><br>
        {metric}: <b>{row['Value']}</b><br>
        Code r√©gion: {row['Code']}<br>
        <small>Cliquer pour plus de d√©tails</small>
        """
        
        folium.CircleMarker(
            location=[row['Latitude'], row['Longitude']],
            radius=normalized_size,
            popup=folium.Popup(popup_text, max_width=200),
            color='white',
            weight=2,
            fillColor=color,
            fillOpacity=0.7
        ).add_to(m)
    
    # Ajouter la l√©gende
    colormap.caption = f'{metric} par r√©gion'
    colormap.add_to(m)
    
    # Affichage dans Streamlit
    map_data = st_folium(m, width=700, height=500)
    
    # Affichage des d√©tails si r√©gion s√©lectionn√©e
    if map_data['last_object_clicked']:
        show_region_details(regions_data, map_data['last_object_clicked'])

def show_region_details(regions_data, clicked_data):
    """Affichage des d√©tails d'une r√©gion s√©lectionn√©e"""
    
    st.markdown("#### üìç R√©gion S√©lectionn√©e")
    
    # Identifier la r√©gion cliqu√©e (approximation par coordonn√©es)
    if 'lat' in clicked_data and 'lng' in clicked_data:
        clicked_lat, clicked_lng = clicked_data['lat'], clicked_data['lng']
        
        # Trouver la r√©gion la plus proche
        distances = regions_data.apply(
            lambda row: ((row['Latitude'] - clicked_lat)**2 + (row['Longitude'] - clicked_lng)**2)**0.5,
            axis=1
        )
        
        closest_region = regions_data.loc[distances.idxmin()]
        
        # Affichage des informations
        col1, col2 = st.columns(2)
        
        with col1:
            st.metric("R√©gion", closest_region['Region'])
            st.metric(closest_region['Metric'], f"{closest_region['Value']}")
            
        with col2:
            # Classement de la r√©gion
            rank = (regions_data['Value'] > closest_region['Value']).sum() + 1
            st.metric("Classement", f"{rank}/{len(regions_data)}")
            
            # √âcart √† la moyenne nationale
            national_avg = regions_data['Value'].mean()
            deviation = closest_region['Value'] - national_avg
            st.metric("Vs Moyenne Nationale", f"{deviation:+.1f}")

def show_geographic_stats(regions_data, metric):
    """Affichage des statistiques g√©ographiques"""
    
    st.markdown("#### üìä Statistiques Nationales")
    
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric("Moyenne", f"{regions_data['Value'].mean():.1f}")
        
    with col2:
        st.metric("M√©diane", f"{regions_data['Value'].median():.1f}")
        
    with col3:
        st.metric("Min", f"{regions_data['Value'].min():.1f}")
        
    with col4:
        st.metric("Max", f"{regions_data['Value'].max():.1f}")
    
    # Top et Bottom 3 r√©gions
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("##### üîù Top 3 R√©gions")
        top_3 = regions_data.nlargest(3, 'Value')[['Region', 'Value']]
        for _, row in top_3.iterrows():
            st.write(f"**{row['Region']}**: {row['Value']}")
    
    with col2:
        st.markdown("##### üîª Bottom 3 R√©gions")
        bottom_3 = regions_data.nsmallest(3, 'Value')[['Region', 'Value']]
        for _, row in bottom_3.iterrows():
            st.write(f"**{row['Region']}**: {row['Value']}")

def show_medical_density_map():
    """Carte de la densit√© m√©dicale"""
    
    st.markdown("### üè• Densit√© des Sp√©cialistes TDAH")
    
    # S√©lecteurs
    col1, col2 = st.columns(2)
    
    with col1:
        specialist_type = st.selectbox(
            "Type de sp√©cialiste",
            ["P√©dopsychiatres", "Neurologues", "Psychiatres", "Tous"]
        )
        
    with col2:
        density_metric = st.selectbox(
            "M√©trique",
            ["Nombre absolu", "Pour 100k habitants", "Pour 1000 enfants"]
        )
    
    # G√©n√©ration des donn√©es de densit√© m√©dicale
    medical_density_data = generate_medical_density_data(specialist_type, density_metric)
    
    # Carte sp√©cialis√©e pour la densit√© m√©dicale
    create_medical_density_map_viz(medical_density_data, specialist_type, density_metric)
    
    # Analyses de corr√©lation
    show_density_correlation_analysis(medical_density_data)

def generate_medical_density_data(specialist_type, density_metric):
    """G√©n√©ration des donn√©es de densit√© m√©dicale"""
    
    regions = [
        '√éle-de-France', 'Centre-Val de Loire', 'Bourgogne-Franche-Comt√©',
        'Normandie', 'Hauts-de-France', 'Grand Est', 'Pays de la Loire',
        'Bretagne', 'Nouvelle-Aquitaine', 'Occitanie', 'Auvergne-Rh√¥ne-Alpes',
        'Provence-Alpes-C√¥te d\'Azur', 'Corse'
    ]
    
    np.random.seed(42)
    
    data = []
    for region in regions:
        
        # Simulation bas√©e sur les caract√©ristiques r√©gionales
        if region == '√éle-de-France':
            base_density = 1.8  # Plus forte densit√© en IdF
        elif region in ['Provence-Alpes-C√¥te d\'Azur', 'Auvergne-Rh√¥ne-Alpes']:
            base_density = 1.2  # Densit√© √©lev√©e dans les grandes m√©tropoles
        elif region in ['Corse', 'Centre-Val de Loire']:
            base_density = 0.4  # Densit√© faible dans les r√©gions peu peupl√©es
        else:
            base_density = 0.8  # Densit√© moyenne
        
        # Variation selon le type de sp√©cialiste
        if specialist_type == "P√©dopsychiatres":
            multiplier = 0.6
        elif specialist_type == "Neurologues":
            multiplier = 1.2
        elif specialist_type == "Psychiatres":
            multiplier = 1.8
        else:  # Tous
            multiplier = 1.0
        
        # Calcul de la valeur finale avec variation al√©atoire
        value = base_density * multiplier * np.random.uniform(0.7, 1.3)
        
        # Ajustement selon la m√©trique
        if density_metric == "Nombre absolu":
            # Conversion en nombre absolu (approximation bas√©e sur la population)
            pop_factor = np.random.randint(500000, 12000000) / 1000000
            value = int(value * pop_factor * 100)
            
        elif density_metric == "Pour 1000 enfants":
            value *= 2.5  # Plus de sp√©cialistes par 1000 enfants que par 100k habitants
        
        data.append({
            'Region': region,
            'Density': round(value, 2),
            'Specialist_Type': specialist_type,
            'Metric': density_metric
        })
    
    return pd.DataFrame(data)

def create_medical_density_map_viz(data, specialist_type, density_metric):
    """Visualisation de la densit√© m√©dicale"""
    
    # Graphique en barres horizontales
    fig = px.bar(
        data.sort_values('Density', ascending=True),
        x='Density',
        y='Region',
        orientation='h',
        title=f'{specialist_type} - {density_metric}',
        color='Density',
        color_continuous_scale='Viridis'
    )
    
    fig.update_layout(height=600, showlegend=False)
    st.plotly_chart(fig, use_container_width=True)
    
    # Carte de chaleur
    st.markdown("#### üå°Ô∏è Carte de Chaleur")
    
    # Cr√©er une matrice pour la heatmap (simulation)
    heatmap_data = data.pivot_table(
        index='Region', 
        values='Density',
        aggfunc='mean'
    ).fillna(0)
    
    fig_heatmap = px.imshow(
        heatmap_data.values.reshape(1, -1),
        x=heatmap_data.index,
        aspect='auto',
        color_continuous_scale='RdYlBu_r',
        title="Intensit√© de la Densit√© M√©dicale"
    )
    
    fig_heatmap.update_layout(height=200)
    fig_heatmap.update_yaxis(showticklabels=False)
    st.plotly_chart(fig_heatmap, use_container_width=True)

def show_density_correlation_analysis(medical_data):
    """Analyse des corr√©lations avec la densit√© m√©dicale"""
    
    st.markdown("#### üîó Corr√©lations avec Autres Indicateurs")
    
    # Simulation de donn√©es corr√©l√©es
    np.random.seed(42)
    
    correlation_data = medical_data.copy()
    
    # Ajouter des variables corr√©l√©es
    correlation_data['Prevalence_TDAH'] = (
        5.9 + (correlation_data['Density'] - correlation_data['Density'].mean()) * 0.3 +
        np.random.normal(0, 0.5, len(correlation_data))
    ).clip(3, 9)
    
    correlation_data['Taux_Diagnostic'] = (
        58 + (correlation_data['Density'] - correlation_data['Density'].mean()) * 5 +
        np.random.normal(0, 8, len(correlation_data))
    ).clip(30, 85)
    
    correlation_data['Temps_Attente_Jours'] = (
        90 - (correlation_data['Density'] - correlation_data['Density'].mean()) * 15 +
        np.random.normal(0, 20, len(correlation_data))
    ).clip(15, 180)
    
    # Graphiques de corr√©lation
    col1, col2 = st.columns(2)
    
    with col1:
        fig_corr1 = px.scatter(
            correlation_data,
            x='Density',
            y='Prevalence_TDAH',
            hover_name='Region',
            title='Densit√© vs Pr√©valence TDAH',
            trendline='ols'
        )
        st.plotly_chart(fig_corr1, use_container_width=True)
    
    with col2:
        fig_corr2 = px.scatter(
            correlation_data,
            x='Density',
            y='Temps_Attente_Jours',
            hover_name='Region',
            title='Densit√© vs Temps d\'Attente',
            trendline='ols'
        )
        st.plotly_chart(fig_corr2, use_container_width=True)
    
    # Matrice de corr√©lation
    corr_matrix = correlation_data[['Density', 'Prevalence_TDAH', 'Taux_Diagnostic', 'Temps_Attente_Jours']].corr()
    
    fig_matrix = px.imshow(
        corr_matrix,
        text_auto=True,
        aspect='auto',
        color_continuous_scale='RdBu_r',
        title='Matrice de Corr√©lation'
    )
    
    st.plotly_chart(fig_matrix, use_container_width=True)

def show_regional_analysis():
    """Analyses d√©taill√©es par r√©gion"""
    
    st.markdown("### üìä Analyses R√©gionales D√©taill√©es")
    
    # S√©lection de r√©gion pour analyse d√©taill√©e
    regions = [
        '√éle-de-France', 'Auvergne-Rh√¥ne-Alpes', 'Hauts-de-France',
        'Nouvelle-Aquitaine', 'Occitanie', 'Grand Est', 'Provence-Alpes-C√¥te d\'Azur',
        'Pays de la Loire', 'Bretagne', 'Normandie', 'Centre-Val de Loire',
        'Bourgogne-Franche-Comt√©', 'Corse'
    ]
    
    selected_region = st.selectbox("S√©lectionner une r√©gion", regions)
    
    # Analyses multi-dimensionnelles pour la r√©gion s√©lectionn√©e
    show_region_deep_dive(selected_region)
    
    # Comparaison avec la moyenne nationale
    show_region_vs_national(selected_region)

def show_region_deep_dive(region_name):
    """Analyse approfondie d'une r√©gion"""
    
    st.markdown(f"#### üîç Analyse D√©taill√©e: {region_name}")
    
    # G√©n√©ration de donn√©es compl√®tes pour la r√©gion
    np.random.seed(hash(region_name) % 2**32)
    
    # Donn√©es simul√©es multi-dimensionnelles
    region_data = {
        'Population_Totale': np.random.randint(1000000, 12000000),
        'Population_6_17_ans': np.random.randint(150000, 2000000),
        'Prevalence_TDAH': round(np.random.normal(5.9, 1.2), 1),
        'Cas_Estimes': np.random.randint(20000, 400000),
        'Taux_Diagnostic': round(np.random.normal(58, 12), 1),
        'Pediatres': np.random.randint(50, 800),
        'Pedopsychiatres': np.random.randint(5, 150),
        'Neurologues': np.random.randint(20, 300),
        'Temps_Attente_Moyens': np.random.randint(30, 120),
        'Prescriptions_Annuelles': np.random.randint(5000, 80000),
        'Cout_Total_Annuel': np.random.randint(10000000, 200000000)
    }
    
    # Affichage des KPIs r√©gionaux
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric("Population 6-17 ans", f"{region_data['Population_6_17_ans']:,}".replace(',', ' '))
        st.metric("Pr√©valence TDAH", f"{region_data['Prevalence_TDAH']}%")
        
    with col2:
        st.metric("Cas Estim√©s", f"{region_data['Cas_Estimes']:,}".replace(',', ' '))
        st.metric("Taux Diagnostic", f"{region_data['Taux_Diagnostic']}%")
        
    with col3:
        st.metric("P√©dopsychiatres", region_data['Pedopsychiatres'])
        st.metric("Temps d'Attente", f"{region_data['Temps_Attente_Moyens']} jours")
        
    with col4:
        st.metric("Prescriptions/an", f"{region_data['Prescriptions_Annuelles']:,}".replace(',', ' '))
        st.metric("Co√ªt Total/an", f"{region_data['Cout_Total_Annuel']/1000000:.1f}M‚Ç¨")
    
    # Graphiques r√©gionaux
    col1, col2 = st.columns(2)
    
    with col1:
        # R√©partition des sp√©cialistes
        specialists_data = pd.DataFrame({
            'Specialite': ['P√©diatres', 'P√©dopsychiatres', 'Neurologues'],
            'Nombre': [region_data['Pediatres'], region_data['Pedopsychiatres'], region_data['Neurologues']]
        })
        
        fig_specialists = px.pie(
            specialists_data,
            values='Nombre',
            names='Specialite',
            title='R√©partition des Sp√©cialistes'
        )
        st.plotly_chart(fig_specialists, use_container_width=True)
    
    with col2:
        # √âvolution temporelle simul√©e
        months = pd.date_range('2023-01', periods=12, freq='M')
        evolution_data = pd.DataFrame({
            'Mois': months,
            'Nouveaux_Diagnostics': np.random.poisson(region_data['Cas_Estimes']/12, 12),
            'Prescriptions': np.random.poisson(region_data['Prescriptions_Annuelles']/12, 12)
        })
        
        fig_evolution = px.line(
            evolution_data,
            x='Mois',
            y=['Nouveaux_Diagnostics', 'Prescriptions'],
            title='√âvolution Mensuelle 2023'
        )
        st.plotly_chart(fig_evolution, use_container_width=True)

def show_region_vs_national(region_name):
    """Comparaison r√©gion vs moyenne nationale"""
    
    st.markdown(f"#### ‚öñÔ∏è {region_name} vs Moyenne Nationale")
    
    # Donn√©es simul√©es pour la comparaison
    np.random.seed(hash(region_name) % 2**32)
    
    comparison_metrics = {
        'Pr√©valence (%)': [np.random.normal(5.9, 1.2), 5.9],
        'Taux Diagnostic (%)': [np.random.normal(58, 12), 58],
        'Sp√©cialistes/100k': [np.random.normal(0.8, 0.3), 0.8],
        'Temps Attente (j)': [np.random.normal(75, 25), 75],
        'Prescriptions/1000': [np.random.normal(12.5, 3), 12.5]
    }
    
    # Graphique radar de comparaison
    categories = list(comparison_metrics.keys())
    region_values = [comparison_metrics[cat][0] for cat in categories]
    national_values = [comparison_metrics[cat][1] for cat in categories]
    
    fig = go.Figure()
    
    fig.add_trace(go.Scatterpolar(
        r=region_values,
        theta=categories,
        fill='toself',
        name=region_name,
        line_color='blue'
    ))
    
    fig.add_trace(go.Scatterpolar(
        r=national_values,
        theta=categories,
        fill='toself',
        name='Moyenne Nationale',
        line_color='red',
        opacity=0.6
    ))
    
    fig.update_layout(
        polar=dict(
            radialaxis=dict(
                visible=True,
                range=[0, max(max(region_values), max(national_values)) * 1.2]
            )),
        showlegend=True,
        title="Comparaison Multi-dimensionnelle"
    )
    
    st.plotly_chart(fig, use_container_width=True)
    
    # Tableau de comparaison d√©taill√©
    comparison_df = pd.DataFrame({
        'M√©trique': categories,
        region_name: [round(val, 1) for val in region_values],
        'Moyenne Nationale': national_values,
        '√âcart': [round(reg - nat, 1) for reg, nat in zip(region_values, national_values)],
        '√âcart (%)': [round((reg - nat) / nat * 100, 1) for reg, nat in zip(region_values, national_values)]
    })
    
    st.dataframe(comparison_df, use_container_width=True)

def show_regional_comparisons():
    """Comparaisons entre r√©gions"""
    
    st.markdown("### üîç Comparaisons Inter-R√©gionales")
    
    # S√©lection de r√©gions √† comparer
    regions = [
        '√éle-de-France', 'Auvergne-Rh√¥ne-Alpes', 'Hauts-de-France',
        'Nouvelle-Aquitaine', 'Occitanie', 'Grand Est', 'Provence-Alpes-C√¥te d\'Azur',
        'Pays de la Loire', 'Bretagne', 'Normandie', 'Centre-Val de Loire',
        'Bourgogne-Franche-Comt√©', 'Corse'
    ]
    
    selected_regions = st.multiselect(
        "S√©lectionner des r√©gions √† comparer (max 5)",
        regions,
        default=['√éle-de-France', 'Auvergne-Rh√¥ne-Alpes', 'Hauts-de-France'],
        max_selections=5
    )
    
    if len(selected_regions) >= 2:
        
        # G√©n√©ration des donn√©es comparatives
        comparison_data = generate_comparative_data(selected_regions)
        
        # M√©triques s√©lectionnables pour comparaison
        metrics_available = [
            'Pr√©valence (%)', 'Taux Diagnostic (%)', 'Densit√© Sp√©cialistes',
            'Temps d\'Attente (j)', 'Prescriptions/1000hab', 'Co√ªt/habitant (‚Ç¨)'
        ]
        
        selected_metric = st.selectbox("M√©trique √† comparer", metrics_available)
        
        # Visualisation comparative
        create_regional_comparison_viz(comparison_data, selected_metric, selected_regions)
        
        # Analyses statistiques
        show_comparison_statistics(comparison_data, selected_regions)
    
    else:
        st.info("S√©lectionnez au moins 2 r√©gions pour effectuer une comparaison")

def generate_comparative_data(regions):
    """G√©n√©ration des donn√©es pour comparaisons"""
    
    comparative_data = {}
    
    for region in regions:
        np.random.seed(hash(region) % 2**32)
        
        comparative_data[region] = {
            'Pr√©valence (%)': round(np.random.normal(5.9, 1.2), 1),
            'Taux Diagnostic (%)': round(np.random.normal(58, 12), 1),
            'Densit√© Sp√©cialistes': round(np.random.normal(0.8, 0.3), 2),
            'Temps d\'Attente (j)': round(np.random.normal(75, 25), 0),
            'Prescriptions/1000hab': round(np.random.normal(12.5, 3), 1),
            'Co√ªt/habitant (‚Ç¨)': round(np.random.normal(145, 40), 0)
        }
    
    return comparative_data

def create_regional_comparison_viz(data, metric, regions):
    """Visualisations comparatives entre r√©gions"""
    
    # Extraction des donn√©es pour la m√©trique s√©lectionn√©e
    metric_data = pd.DataFrame({
        'Region': regions,
        'Value': [data[region][metric] for region in regions]
    })
    
    col1, col2 = st.columns(2)
    
    with col1:
        # Graphique en barres
        fig_bar = px.bar(
            metric_data,
            x='Region',
            y='Value',
            title=f'Comparaison - {metric}',
            color='Value',
            color_continuous_scale='Viridis'
        )
        fig_bar.update_xaxis(tickangle=45)
        st.plotly_chart(fig_bar, use_container_width=True)
    
    with col2:
        # Graphique radar pour comparaison multi-m√©triques
        if len(regions) <= 4:  # Limiter pour la lisibilit√©
            
            fig_radar = go.Figure()
            
            metrics = ['Pr√©valence (%)', 'Taux Diagnostic (%)', 'Densit√© Sp√©cialistes']
            
            for region in regions:
                values = [data[region][m] for m in metrics]
                
                fig_radar.add_trace(go.Scatterpolar(
                    r=values,
                    theta=metrics,
                    fill='toself',
                    name=region,
                    opacity=0.6
                ))
            
            fig_radar.update_layout(
                polar=dict(radialaxis=dict(visible=True)),
                showlegend=True,
                title="Comparaison Multi-M√©triques"
            )
            
            st.plotly_chart(fig_radar, use_container_width=True)
        
        else:
            # Graphique en ligne pour √©viter la surcharge
            fig_line = px.line(
                metric_data,
                x='Region',
                y='Value',
                title=f'√âvolution - {metric}',
                markers=True
            )
            fig_line.update_xaxis(tickangle=45)
            st.plotly_chart(fig_line, use_container_width=True)

def show_comparison_statistics(data, regions):
    """Statistiques de comparaison"""
    
    st.markdown("#### üìä Statistiques Comparatives")
    
    # Cr√©er un DataFrame complet pour les analyses
    full_data = pd.DataFrame(data).T
    
    # Statistiques descriptives
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("##### üìà Statistiques Descriptives")
        stats = full_data.describe()
        st.dataframe(stats.round(2))
    
    with col2:
        st.markdown("##### üèÜ Classements")
        
        # Classement pour chaque m√©trique
        rankings = {}
        for metric in full_data.columns:
            sorted_regions = full_data.sort_values(metric, ascending=False).index.tolist()
            rankings[metric] = {region: idx+1 for idx, region in enumerate(sorted_regions)}
        
        # Affichage du classement pour une m√©trique exemple
        ranking_df = pd.DataFrame({
            'R√©gion': regions,
            'Rang Pr√©valence': [rankings['Pr√©valence (%)'][region] for region in regions],
            'Rang Diagnostic': [rankings['Taux Diagnostic (%)'][region] for region in regions]
        })
        
        st.dataframe(ranking_df)
    
    # Corr√©lations entre m√©triques
    st.markdown("##### üîó Corr√©lations entre M√©triques")
    
    corr_matrix = full_data.corr()
    
    fig_corr = px.imshow(
        corr_matrix,
        text_auto=True,
        aspect='auto',
        color_continuous_scale='RdBu_r',
        title='Matrice de Corr√©lation entre M√©triques'
    )
    
    st.plotly_chart(fig_corr, use_container_width=True)