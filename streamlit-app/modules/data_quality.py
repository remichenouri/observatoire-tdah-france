"""
Module Qualit√© des Donn√©es - Observatoire TDAH
Inspection, nettoyage et validation de la qualit√© des donn√©es
"""

import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
import plotly.figure_factory as ff
from plotly.subplots import make_subplots
try:
    import seaborn as sns
    HAS_SEABORN = True
except ImportError:
    HAS_SEABORN = False
    import matplotlib.pyplot as plt
import matplotlib.pyplot as plt
from datetime import datetime
import io

def show_data_quality():
    """Interface principale de qualit√© des donn√©es"""
    
    st.markdown("# üîç Qualit√© des Donn√©es")
    st.markdown("Inspection, validation et nettoyage des donn√©es TDAH")
    
    # Score de qualit√© global
    show_quality_overview()
    
    # Navigation par onglets
    tab1, tab2, tab3, tab4, tab5 = st.tabs([
        "üìä Vue d'ensemble",
        "üîé Inspection D√©taill√©e", 
        "üõ†Ô∏è Nettoyage",
        "‚úÖ Validation",
        "üìã Rapport"
    ])
    
    with tab1:
        show_quality_dashboard()
    
    with tab2:
        show_detailed_inspection()
        
    with tab3:
        show_data_cleaning()
        
    with tab4:
        show_validation_results()
        
    with tab5:
        show_quality_report()

def show_quality_overview():
    """Score global de qualit√©"""
    
    st.markdown("## üéØ Score de Qualit√© Global")
    
    # Calcul du score composite
    quality_metrics = {
        'Compl√©tude': 94.2,
        'Exactitude': 96.8,
        'Coh√©rence': 91.5,
        'Actualit√©': 98.1,
        'Validit√©': 93.7
    }
    
    # Score global pond√©r√©
    weights = {'Compl√©tude': 0.25, 'Exactitude': 0.25, 'Coh√©rence': 0.2, 'Actualit√©': 0.15, 'Validit√©': 0.15}
    overall_score = sum(quality_metrics[k] * weights[k] for k in quality_metrics)
    
    # Affichage du score principal
    col1, col2 = st.columns([1, 2])
    
    with col1:
        # Jauge de score
        fig = go.Figure(go.Indicator(
            mode = "gauge+number+delta",
            value = overall_score,
            domain = {'x': [0, 1], 'y': [0, 1]},
            title = {'text': "Score Qualit√© Global"},
            delta = {'reference': 92},
            gauge = {
                'axis': {'range': [0, 100]},
                'bar': {'color': "darkblue"},
                'steps': [
                    {'range': [0, 50], 'color': "lightgray"},
                    {'range': [50, 80], 'color': "yellow"},
                    {'range': [80, 100], 'color': "green"}
                ],
                'threshold': {
                    'line': {'color': "red", 'width': 4},
                    'thickness': 0.75,
                    'value': 90
                }
            }
        ))
        
        fig.update_layout(height=300)
        st.plotly_chart(fig, use_container_width=True)
    
    with col2:
        # D√©tail par dimension
        st.markdown("#### üìã D√©tail par Dimension")
        
        for metric, score in quality_metrics.items():
            # Couleur selon le score
            if score >= 95:
                color = "üü¢"
            elif score >= 85:
                color = "üü°"
            else:
                color = "üî¥"
            
            col_a, col_b = st.columns([3, 1])
            with col_a:
                st.metric(f"{color} {metric}", f"{score}%")

def show_quality_dashboard():
    """Dashboard de qualit√© d√©taill√©"""
    
    st.markdown("### üìä Tableau de Bord Qualit√©")
    
    # G√©n√©ration de donn√©es de test r√©alistes
    datasets = generate_test_data()
    
    # S√©lecteur de dataset
    selected_dataset = st.selectbox(
        "Choisir un dataset",
        list(datasets.keys()),
        index=0
    )
    
    df = datasets[selected_dataset]
    
    # M√©triques par dataset
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric("üìè Lignes", f"{len(df):,}")
        
    with col2:
        st.metric("üìä Colonnes", len(df.columns))
        
    with col3:
        missing_pct = (df.isnull().sum().sum() / (len(df) * len(df.columns)) * 100)
        st.metric("‚ùì Valeurs Manquantes", f"{missing_pct:.1f}%")
        
    with col4:
        duplicates = df.duplicated().sum()
        st.metric("üîÑ Doublons", duplicates)
    
    # Visualisations
    col1, col2 = st.columns(2)
    
    with col1:
        # Heatmap des valeurs manquantes
        st.markdown("#### üî• Carte des Valeurs Manquantes")
        create_missing_heatmap(df)
    
    with col2:
        # Graphique de distribution des types de donn√©es
        st.markdown("#### üìà Types de Donn√©es")
        create_dtype_chart(df)

def create_missing_heatmap(df):
    """Cr√©er la heatmap des valeurs manquantes"""
    
    # Calculer le pourcentage de valeurs manquantes par colonne
    missing_data = df.isnull().sum().sort_values(ascending=False)
    missing_pct = (missing_data / len(df) * 100).round(1)
    
    if missing_pct.sum() > 0:
        # Graphique en barres des valeurs manquantes
        fig = px.bar(
            x=missing_pct.values,
            y=missing_pct.index,
            orientation='h',
            title='Pourcentage de Valeurs Manquantes par Colonne',
            color=missing_pct.values,
            color_continuous_scale='Reds'
        )
        
        fig.update_layout(height=400)
        st.plotly_chart(fig, use_container_width=True)
    else:
        st.success("‚úÖ Aucune valeur manquante d√©tect√©e!")

def create_dtype_chart(df):
    """Graphique des types de donn√©es"""
    
    # Compter les types de donn√©es
    dtype_counts = df.dtypes.value_counts()
    
    fig = px.pie(
        values=dtype_counts.values,
        names=dtype_counts.index.astype(str),
        title='R√©partition des Types de Donn√©es'
    )
    
    fig.update_layout(height=400)
    st.plotly_chart(fig, use_container_width=True)

def show_detailed_inspection():
    """Inspection d√©taill√©e des donn√©es"""
    
    st.markdown("### üîé Inspection D√©taill√©e")
    
    # G√©n√©ration de donn√©es de test
    datasets = generate_test_data()
    
    # S√©lection dataset et colonne
    col1, col2 = st.columns(2)
    
    with col1:
        selected_dataset = st.selectbox("Dataset", list(datasets.keys()), key="inspect")
    
    df = datasets[selected_dataset]
    
    with col2:
        selected_column = st.selectbox("Colonne", df.columns)
    
    # Analyse de la colonne s√©lectionn√©e
    st.markdown(f"#### üìä Analyse: {selected_column}")
    
    col_data = df[selected_column]
    
    # M√©triques de base
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric("Type", str(col_data.dtype))
        
    with col2:
        st.metric("Non-nulls", f"{col_data.notna().sum():,}")
        
    with col3:
        st.metric("Nulls", f"{col_data.isna().sum():,}")
        
    with col4:
        if pd.api.types.is_numeric_dtype(col_data):
            st.metric("Unique", col_data.nunique())
        else:
            st.metric("Unique", col_data.nunique())
    
    # Visualisations selon le type
    if pd.api.types.is_numeric_dtype(col_data):
        show_numeric_analysis(col_data, selected_column)
    else:
        show_categorical_analysis(col_data, selected_column)

def show_numeric_analysis(col_data, col_name):
    """Analyse pour colonnes num√©riques"""
    
    col1, col2 = st.columns(2)
    
    with col1:
        # Statistiques descriptives
        st.markdown("#### üìà Statistiques Descriptives")
        stats = col_data.describe()
        st.dataframe(stats.to_frame().T)
        
        # D√©tection des outliers
        Q1 = col_data.quantile(0.25)
        Q3 = col_data.quantile(0.75)
        IQR = Q3 - Q1
        outliers = col_data[(col_data < Q1 - 1.5*IQR) | (col_data > Q3 + 1.5*IQR)]
        
        st.metric("üîç Outliers", len(outliers))
    
    with col2:
        # Distribution
        st.markdown("#### üìä Distribution")
        fig = px.histogram(col_data.dropna(), nbins=30, title=f'Distribution - {col_name}')
        st.plotly_chart(fig, use_container_width=True)
        
    # Box plot
    st.markdown("#### üì¶ Box Plot")
    fig = px.box(y=col_data, title=f'Box Plot - {col_name}')
    st.plotly_chart(fig, use_container_width=True)

def show_categorical_analysis(col_data, col_name):
    """Analyse pour colonnes cat√©gorielles"""
    
    col1, col2 = st.columns(2)
    
    with col1:
        # Top valeurs
        st.markdown("#### üèÜ Top Valeurs")
        top_values = col_data.value_counts().head(10)
        st.dataframe(top_values.to_frame('Count'))
        
    with col2:
        # Distribution
        st.markdown("#### üìä Distribution")
        fig = px.bar(
            x=top_values.values,
            y=top_values.index,
            orientation='h',
            title=f'Top 10 - {col_name}'
        )
        st.plotly_chart(fig, use_container_width=True)

def show_data_cleaning():
    """Interface de nettoyage des donn√©es"""
    
    st.markdown("### üõ†Ô∏è Nettoyage des Donn√©es")
    
    # Options de nettoyage
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("#### üîß Options de Nettoyage")
        
        clean_missing = st.checkbox("Traiter les valeurs manquantes", value=True)
        clean_duplicates = st.checkbox("Supprimer les doublons", value=True)
        clean_outliers = st.checkbox("Traiter les outliers", value=False)
        standardize_formats = st.checkbox("Standardiser les formats", value=True)
        
        if clean_missing:
            missing_strategy = st.selectbox(
                "Strat√©gie valeurs manquantes",
                ["Suppression", "Imputation par moyenne", "Imputation par m√©diane", "Machine Learning"]
            )
    
    with col2:
        st.markdown("#### ‚öôÔ∏è Param√®tres Avanc√©s")
        
        outlier_method = st.selectbox("M√©thode outliers", ["IQR", "Z-score", "Isolation Forest"])
        outlier_threshold = st.slider("Seuil outliers", 1.0, 5.0, 3.0)
        
        date_format = st.text_input("Format date cible", "YYYY-MM-DD")
        encoding_target = st.selectbox("Encodage cible", ["UTF-8", "ISO-8859-1", "ASCII"])
    
    # Simulation du nettoyage
    if st.button("üöÄ Lancer le Nettoyage", type="primary"):
        run_data_cleaning(clean_missing, clean_duplicates, missing_strategy)

def run_data_cleaning(clean_missing, clean_duplicates, missing_strategy):
    """Simulation du processus de nettoyage"""
    
    progress_bar = st.progress(0)
    status_text = st.empty()
    
    steps = [
        "üîç Analyse des donn√©es...",
        "‚ùì Traitement des valeurs manquantes...",
        "üîÑ Suppression des doublons...",
        "üßπ Standardisation des formats...",
        "‚úÖ Nettoyage termin√©!"
    ]
    
    for i, step in enumerate(steps):
        status_text.text(step)
        progress_bar.progress((i + 1) / len(steps))
        
        # Simulation avec sleep r√©duit
        import time
        time.sleep(0.5)
    
    # R√©sultats simul√©s
    st.success("‚úÖ Nettoyage termin√© avec succ√®s!")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.metric("Lignes supprim√©es", "1,247", delta="-5.2%")
        
    with col2:
        st.metric("Valeurs imput√©es", "3,891", delta="Compl√©t√©")
        
    with col3:
        st.metric("Score qualit√©", "96.8%", delta="+4.3%")

def show_validation_results():
    """R√©sultats de validation"""
    
    st.markdown("### ‚úÖ R√©sultats de Validation")
    
    # Tests de validation
    validation_tests = pd.DataFrame({
        'Test': [
            'Format des codes r√©gion',
            'Coh√©rence des dates',
            'Valeurs dans les intervalles',
            'Unicit√© des identifiants',
            'Compl√©tude des champs obligatoires',
            'Format des codes postaux',
            'Validation des emails'
        ],
        'Statut': ['‚úÖ Pass√©', '‚úÖ Pass√©', '‚ö†Ô∏è Avertissement', '‚úÖ Pass√©', '‚ùå √âchec', '‚úÖ Pass√©', '‚úÖ Pass√©'],
        'Score': [100, 100, 85, 100, 72, 100, 98],
        'Erreurs': [0, 0, 156, 0, 2847, 0, 23]
    })
    
    st.dataframe(validation_tests, use_container_width=True)
    
    # Graphique de r√©partition des r√©sultats
    status_counts = validation_tests['Statut'].str.extract(r'([‚úÖ‚ö†Ô∏è‚ùå])').value_counts()
    
    fig = px.pie(
        values=status_counts.values,
        names=['Pass√©', 'Avertissement', '√âchec'],
        title='R√©partition des Tests de Validation',
        color_discrete_map={'Pass√©': 'green', 'Avertissement': 'orange', '√âchec': 'red'}
    )
    
    st.plotly_chart(fig, use_container_width=True)

def show_quality_report():
    """G√©n√©ration du rapport de qualit√©"""
    
    st.markdown("### üìã Rapport de Qualit√©")
    
    # Options du rapport
    col1, col2 = st.columns(2)
    
    with col1:
        report_type = st.radio(
            "Type de rapport",
            ["R√©sum√© ex√©cutif", "Rapport d√©taill√©", "Rapport technique"]
        )
        
        include_charts = st.checkbox("Inclure les graphiques", value=True)
        include_recommendations = st.checkbox("Inclure les recommandations", value=True)
        
    with col2:
        export_format = st.selectbox("Format d'export", ["PDF", "HTML", "Word", "Excel"])
        
        if st.button("üì• G√©n√©rer le Rapport", type="primary"):
            generate_quality_report(report_type, include_charts, include_recommendations, export_format)

def generate_quality_report(report_type, include_charts, include_recommendations, export_format):
    """G√©n√©ration du rapport de qualit√©"""
    
    with st.spinner("G√©n√©ration du rapport en cours..."):
        import time
        time.sleep(2)
        
        st.success(f"‚úÖ Rapport {report_type} g√©n√©r√© en format {export_format}!")
        
        # Simulation du contenu du rapport
        report_content = f"""
        # Rapport de Qualit√© des Donn√©es - Observatoire TDAH
        
        **Date:** {datetime.now().strftime('%Y-%m-%d')}
        **Type:** {report_type}
        
        ## R√©sum√© Ex√©cutif
        - Score global de qualit√©: 94.6%
        - Datasets analys√©s: 5
        - Tests de validation: 7 (5 pass√©s, 1 avertissement, 1 √©chec)
        
        ## Recommandations Prioritaires
        1. Am√©liorer la compl√©tude des champs obligatoires (72% ‚Üí 95%)
        2. Standardiser les formats de codes r√©gion
        3. Mettre en place une validation en temps r√©el
        """
        
        st.text_area("Aper√ßu du rapport", report_content, height=300)
        
        # Bouton de t√©l√©chargement simul√©
        st.download_button(
            label=f"üíæ T√©l√©charger {export_format}",
            data=report_content,
            file_name=f"rapport_qualite_{datetime.now().strftime('%Y%m%d')}.txt",
            mime="text/plain"
        )

def generate_test_data():
    """G√©n√©ration de donn√©es de test pour la d√©monstration"""
    
    np.random.seed(42)
    
    datasets = {}
    
    # Dataset √©pid√©miologique
    epidemio_data = pd.DataFrame({
        'region_code': np.random.choice(['11', '32', '44', '75', '76'], 1000),
        'age_group': np.random.choice(['6-11', '12-17', '18-25'], 1000),
        'sexe': np.random.choice(['M', 'F'], 1000),
        'diagnostic_confirme': np.random.choice([0, 1, np.nan], 1000, p=[0.3, 0.6, 0.1]),
        'date_diagnostic': pd.date_range('2020-01-01', periods=1000, freq='D'),
        'severite': np.random.choice(['Leger', 'Modere', 'Severe', np.nan], 1000, p=[0.4, 0.4, 0.15, 0.05])
    })
    
    datasets['Donn√©es √âpid√©miologiques'] = epidemio_data
    
    # Dataset prescriptions
    prescriptions_data = pd.DataFrame({
        'code_cip': np.random.randint(1000000, 9999999, 500),
        'methylphenidate_mg': np.random.choice([10, 18, 27, 36, 54], 500),
        'nb_boites': np.random.randint(1, 6, 500),
        'date_delivrance': pd.date_range('2023-01-01', periods=500, freq='D'),
        'age_patient': np.random.randint(6, 65, 500),
        'prescripteur_specialite': np.random.choice(['Pediatre', 'Neurologue', 'Psychiatre', np.nan], 500, p=[0.4, 0.3, 0.25, 0.05])
    })
    
    datasets['Donn√©es Prescriptions'] = prescriptions_data
    
    return datasets
