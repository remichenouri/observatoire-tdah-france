# üß† Observatoire TDAH - Application Streamlit

Application web sophistiqu√©e pour la visualisation, l'analyse et le monitoring des donn√©es TDAH en France. Cette application moderne offre une interface intuitive pour les professionnels de sant√©, chercheurs et administrateurs.

## üöÄ Fonctionnalit√©s Principales

### üìä Dashboard Principal
- **KPIs en temps r√©el** : Pr√©valence, cas estim√©s, couverture r√©gionale
- **Visualisations interactives** : Graphiques Plotly, cartes, m√©triques
- **Analyses multi-dimensionnelles** : D√©mographie, syst√®me de soins, √©conomie
- **Monitoring de la qualit√©** : Scores de qualit√© des donn√©es en continu

### üîÑ Collecte de Donn√©es Automatis√©e
- **Sources multiples** : DREES, INSEE, ANSM, donn√©es hospitali√®res
- **Interface de monitoring** : Suivi en temps r√©el des collectes
- **Configuration flexible** : Param√©trage des APIs et fr√©quences
- **Historique complet** : Tra√ßabilit√© de toutes les op√©rations

### üîç Gestion de la Qualit√©
- **Inspection automatique** : D√©tection des anomalies et valeurs manquantes
- **Nettoyage intelligent** : ML pour l'imputation des donn√©es
- **Validation en continu** : Tests de coh√©rence et d'int√©grit√©
- **Rapports d√©taill√©s** : Export des analyses qualit√©

### üó∫Ô∏è Cartographie Interactive
- **Visualisations g√©ographiques** : Folium, donn√©es r√©gionales
- **Densit√© m√©dicale** : R√©partition des sp√©cialistes
- **Analyses territoriales** : Comparaisons inter-r√©gionales

### üíä Analyses des Prescriptions
- **Tendances temporelles** : √âvolution des prescriptions
- **Analyses par mol√©cule** : M√©thylph√©nidate, Atomox√©tine, etc.
- **Profils patients** : Segmentation par √¢ge, r√©gion, pathologie

### üîß Administration Avanc√©e
- **Gestion utilisateurs** : R√¥les, permissions, authentification
- **Configuration syst√®me** : APIs, param√®tres, notifications
- **Monitoring technique** : CPU, m√©moire, services
- **Maintenance** : Sauvegardes, nettoyage, optimisation

## üèóÔ∏è Architecture Technique

### Structure Modulaire
```
observatoire-tdah-streamlit/
‚îú‚îÄ‚îÄ app.py                          # Application principale
‚îú‚îÄ‚îÄ requirements.txt                # D√©pendances Python
‚îú‚îÄ‚îÄ README.md                      # Documentation
‚îú‚îÄ‚îÄ .streamlit/
‚îÇ   ‚îî‚îÄ‚îÄ config.toml               # Configuration Streamlit
‚îú‚îÄ‚îÄ modules/                      # Modules fonctionnels
‚îÇ   ‚îú‚îÄ‚îÄ dashboard.py             # Dashboard principal
‚îÇ   ‚îú‚îÄ‚îÄ data_collection.py       # Collecte de donn√©es
‚îÇ   ‚îú‚îÄ‚îÄ data_quality.py          # Qualit√© des donn√©es
‚îÇ   ‚îú‚îÄ‚îÄ epidemiology.py          # Analyses √©pid√©miologiques
‚îÇ   ‚îú‚îÄ‚îÄ mapping.py               # Cartographie
‚îÇ   ‚îú‚îÄ‚îÄ prescriptions.py         # Analyses prescriptions
‚îÇ   ‚îî‚îÄ‚îÄ admin.py                 # Administration
‚îú‚îÄ‚îÄ utils/                       # Utilitaires
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ data_loader.py           # Chargement des donn√©es
‚îÇ   ‚îú‚îÄ‚îÄ visualization.py         # Fonctions de visualisation
‚îÇ   ‚îú‚îÄ‚îÄ config.py                # Configuration globale
‚îÇ   ‚îî‚îÄ‚îÄ constants.py             # Constantes du projet
‚îú‚îÄ‚îÄ core/                        # Logique m√©tier
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ observatoire_collector.py # Collecteur principal
‚îÇ   ‚îú‚îÄ‚îÄ standardisation.py       # Standardisation des donn√©es
‚îÇ   ‚îú‚îÄ‚îÄ missing_values.py        # Gestion valeurs manquantes
‚îÇ   ‚îî‚îÄ‚îÄ inspection.py            # Inspection des donn√©es
‚îî‚îÄ‚îÄ data/                        # Donn√©es et cache
    ‚îú‚îÄ‚îÄ raw/                     # Donn√©es brutes
    ‚îú‚îÄ‚îÄ processed/               # Donn√©es trait√©es
    ‚îî‚îÄ‚îÄ cache/                   # Cache temporaire
```

### Technologies Utilis√©es
- **Frontend** : Streamlit 1.28+, Plotly, Folium
- **Data Science** : Pandas 2.0+, NumPy, Scikit-learn
- **Visualisation** : Plotly Express, Seaborn, Matplotlib
- **Base de donn√©es** : SQLAlchemy, PostgreSQL
- **APIs** : Requests, authentification OAuth2
- **D√©ploiement** : Docker, Streamlit Cloud

## üîß Installation et Configuration

### 1. Pr√©requis
```bash
# Python 3.9+ requis
python --version
# Git install√©
git --version
```

### 2. Clonage et Setup
```bash
# Cloner le repository Observatoire TDAH
git clone https://github.com/votre-username/observatoire-tdah.git
cd observatoire-tdah

# Cr√©er le dossier Streamlit
mkdir streamlit-app
cd streamlit-app

# Cr√©er l'environnement virtuel
python -m venv venv

# Activer l'environnement (Windows)
venv\Scripts\activate
# Ou sur Linux/Mac
source venv/bin/activate
```

### 3. Installation des D√©pendances
```bash
# Installer les packages requis
pip install -r requirements.txt

# V√©rifier l'installation
streamlit --version
```

### 4. Structure des Dossiers
```bash
# Cr√©er la structure compl√®te
mkdir -p modules utils core data/{raw,processed,cache} .streamlit

# Copier les fichiers fournis
# app.py, requirements.txt, README.md dans le r√©pertoire racine
# Modules Python dans leurs dossiers respectifs
```

### 5. Configuration
```bash
# Cr√©er le fichier de configuration Streamlit
cat > .streamlit/config.toml << EOF
[global]
developmentMode = false

[server]
runOnSave = true
port = 8501
enableCORS = false
enableXsrfProtection = false

[browser]
gatherUsageStats = false

[theme]
primaryColor = "#667eea"
backgroundColor = "#ffffff"
secondaryBackgroundColor = "#f0f2f6"
textColor = "#262730"
font = "sans serif"
EOF
```

### 6. Variables d'Environnement
```bash
# Cr√©er le fichier .env pour les cl√©s API
cat > .env << EOF
# API Keys (remplacer par vos vraies cl√©s)
DREES_API_KEY=your_drees_api_key
INSEE_API_KEY=your_insee_api_key
ANSM_API_KEY=your_ansm_api_key

# Base de donn√©es
DATABASE_URL=postgresql://user:password@localhost/observatoire_tdah

# Configuration
DEBUG_MODE=false
ADMIN_PASSWORD=your_secure_admin_password
SECRET_KEY=your_secret_key_for_sessions
EOF
```

## üöÄ Lancement de l'Application

### Mode D√©veloppement
```bash
# Lancer l'application en mode d√©veloppement
streamlit run app.py

# Ou avec des options sp√©cifiques
streamlit run app.py --server.port=8501 --server.address=0.0.0.0
```

### Mode Production
```bash
# Installer Gunicorn pour la production
pip install gunicorn

# Lancer avec Gunicorn (optionnel, Streamlit peut tourner seul)
streamlit run app.py --server.headless=true --server.port=8501
```

### Docker (Recommand√© pour Production)
```dockerfile
# Cr√©er le Dockerfile
FROM python:3.11-slim

WORKDIR /app

COPY requirements.txt .
RUN pip install -r requirements.txt

COPY . .

EXPOSE 8501

HEALTHCHECK CMD curl --fail http://localhost:8501/_stcore/health

ENTRYPOINT ["streamlit", "run", "app.py", "--server.port=8501", "--server.address=0.0.0.0"]
```

```bash
# Build et run avec Docker
docker build -t observatoire-tdah-streamlit .
docker run -p 8501:8501 observatoire-tdah-streamlit
```

## üîó Int√©gration avec le Projet Existant

### 1. Int√©gration des Collecteurs
```python
# Dans core/observatoire_collector.py
# Utiliser votre classe ObservatoireTDAHCollector existante
from your_existing_project.observatoire_collector import ObservatoireTDAHCollector

# Adapter l'interface Streamlit pour utiliser vos vrais collecteurs
collector = ObservatoireTDAHCollector()
data = collector.collecter_toutes_donnees()
```

### 2. Int√©gration Base de Donn√©es
```python
# Configuration de la base de donn√©es
import sqlalchemy as sa
from sqlalchemy import create_engine

# Utiliser votre sch√©ma de base existant
engine = create_engine(os.getenv('DATABASE_URL'))

# Adapter les requ√™tes pour vos tables
def load_epidemiology_data():
    query = """
    SELECT region_code, prevalence_rate, cases_estimated
    FROM your_epidemiology_table
    WHERE date_collected >= current_date - interval '30 days'
    """
    return pd.read_sql(query, engine)
```

### 3. Int√©gration APIs
```python
# Utiliser vos configurations API existantes
from your_project.config import API_CREDENTIALS

# Adapter les collecteurs dans data_collection.py
def collect_drees_data():
    headers = {'Authorization': f'Bearer {API_CREDENTIALS["drees"]}'}
    # Votre logique de collecte existante
```

## üìä Utilisation de l'Application

### Interface Utilisateur
1. **Navigation** : Menu lat√©ral avec 7 modules principaux
2. **Dashboard** : Vue d'ensemble avec KPIs temps r√©el
3. **Collecte** : Monitoring et lancement des collectes
4. **Qualit√©** : Inspection et nettoyage des donn√©es
5. **Analyses** : Visualisations √©pid√©miologiques avanc√©es
6. **Cartographie** : Visualisations g√©ographiques interactives
7. **Administration** : Gestion compl√®te du syst√®me

### Authentification
```python
# Mode d√©monstration (√† remplacer en production)
# Admin : admin / tdah2024
# Utilisateur : demo / demo123

# Int√©grer votre syst√®me d'authentification existant
def authenticate_user(username, password):
    # Votre logique d'authentification
    return validate_credentials(username, password)
```

## üõ†Ô∏è Personnalisation et Extension

### Ajout de Nouveaux Modules
```python
# Cr√©er un nouveau module dans modules/
def show_new_module():
    st.markdown("# üÜï Nouveau Module")
    # Votre logique m√©tier

# Ajouter dans app.py
elif page == "üÜï Nouveau Module":
    from modules.new_module import show_new_module
    show_new_module()
```

### Personnalisation des Visualisations
```python
# Dans utils/visualization.py
def create_custom_plot(data, plot_type):
    # Vos visualisations personnalis√©es
    fig = px.scatter(data, x='age', y='severity')
    return fig
```

### Ajout de Sources de Donn√©es
```python
# Dans modules/data_collection.py
def add_custom_data_source():
    # Interface pour ajouter vos sources sp√©cifiques
    source_config = {
        'name': st.text_input("Nom de la source"),
        'url': st.text_input("URL de l'API"),
        'auth_type': st.selectbox("Type d'auth", ["API Key", "OAuth2"])
    }
```

## üîí S√©curit√© et Bonnes Pratiques

### Authentification S√©curis√©e
```python
# Remplacer l'authentification de d√©mo par un vrai syst√®me
import streamlit_authenticator as stauth

# Configuration avec hachage des mots de passe
config = {
    'credentials': {
        'usernames': {
            'admin': {
                'email': 'admin@observatoire-tdah.fr',
                'name': 'Administrateur',
                'password': '$2b$12$...',  # Hash bcrypt
            }
        }
    }
}

authenticator = stauth.Authenticate(config)
```

### Protection des Donn√©es
```python
# Chiffrement des donn√©es sensibles
import cryptography.fernet as fernet

key = os.getenv('ENCRYPTION_KEY')
cipher = fernet.Fernet(key)

# Chiffrer les donn√©es sensibles avant stockage
encrypted_data = cipher.encrypt(sensitive_data.encode())
```

### Gestion des Sessions
```python
# Sessions s√©curis√©es avec timeout
if 'session_start' not in st.session_state:
    st.session_state.session_start = datetime.now()

# V√©rifier l'expiration
session_duration = datetime.now() - st.session_state.session_start
if session_duration > timedelta(hours=8):
    # Forcer la re-authentification
    st.session_state.authenticated = False
```

## üìà Performance et Optimisation

### Cache Streamlit
```python
# Utiliser le cache pour les donn√©es lourdes
@st.cache_data(ttl=3600)  # Cache 1 heure
def load_epidemiology_data():
    # Chargement des donn√©es co√ªteuses
    return pd.read_sql(query, connection)

@st.cache_resource
def init_database_connection():
    # Initialisation connexion DB (partag√©e)
    return create_engine(DATABASE_URL)
```

### Optimisation des Visualisations
```python
# √âchantillonnage pour les gros datasets
def optimize_plot_data(df, max_points=10000):
    if len(df) > max_points:
        return df.sample(max_points)
    return df

# Utilisation de Plotly optimis√©
fig = px.scatter(optimize_plot_data(df), x='x', y='y')
fig.update_layout(showlegend=False)  # R√©duire la charge
```

## üöÄ D√©ploiement en Production

### Streamlit Cloud
```bash
# 1. Pusher le code sur GitHub
git add .
git commit -m "Application Streamlit Observatoire TDAH"
git push origin main

# 2. D√©ployer sur Streamlit Cloud
# - Aller sur share.streamlit.io
# - Connecter votre repository GitHub
# - Sp√©cifier app.py comme fichier principal
# - Configurer les secrets (API keys, etc.)
```

### Heroku
```bash
# Cr√©er le Procfile
echo "web: streamlit run app.py --server.port=\$PORT --server.address=0.0.0.0" > Procfile

# D√©ploiement
heroku create observatoire-tdah-app
git push heroku main
```

### AWS/Azure
```bash
# Configuration Docker pour cloud
docker build -t observatoire-tdah .
docker tag observatoire-tdah your-registry/observatoire-tdah:latest
docker push your-registry/observatoire-tdah:latest

# D√©ploiement avec Kubernetes ou Container Instances
```

## üìù Maintenance et Monitoring

### Logs et Monitoring
```python
# Configuration du logging
import logging

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('app.log'),
        logging.StreamHandler()
    ]
)

logger = logging.getLogger(__name__)

# Dans vos fonctions
def collect_data():
    logger.info("D√©but de collecte de donn√©es")
    try:
        # Logique de collecte
        logger.info(f"Collecte r√©ussie: {len(data)} enregistrements")
    except Exception as e:
        logger.error(f"Erreur collecte: {str(e)}")
```

### M√©triques d'Usage
```python
# Tracking des interactions utilisateurs
def track_user_action(action, user_id, details=None):
    metrics = {
        'timestamp': datetime.now(),
        'action': action,
        'user_id': user_id,
        'details': details
    }
    
    # Sauvegarder en base ou envoyer √† un service d'analytics
    save_user_metrics(metrics)
```

### Sauvegarde Automatique
```python
# Script de sauvegarde (crontab ou scheduled task)
def backup_system():
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    
    # Sauvegarde base de donn√©es
    os.system(f'pg_dump {DATABASE_URL} > backup_{timestamp}.sql')
    
    # Sauvegarde fichiers de donn√©es
    shutil.make_archive(f'data_backup_{timestamp}', 'zip', 'data/')
    
    # Upload vers stockage cloud (AWS S3, Azure Blob, etc.)
    upload_to_cloud_storage(f'backup_{timestamp}.sql')
```

## ü§ù Support et Contact

### Documentation Technique
- **API Documentation** : `/docs` endpoint
- **Code Source** : Repository GitHub avec README d√©taill√©
- **Exemples** : Notebooks Jupyter dans `/examples`

### Support Utilisateurs
- **Guide Utilisateur** : Documentation int√©gr√©e dans l'app
- **FAQ** : Section aide dans le menu
- **Tickets** : Syst√®me de ticketing int√©gr√© pour le support

### Contact D√©veloppement
- **Email** : dev@observatoire-tdah.fr
- **Issues GitHub** : Pour bugs et am√©liorations
- **Documentation** : Wiki du projet pour guides avanc√©s

---

## üéØ Pr√™t pour l'Emploi

Cette application Streamlit sophistiqu√©e d√©montre :

‚úÖ **Expertise technique** : Python avanc√©, Streamlit, Data Science stack complet  
‚úÖ **Architecture modulaire** : Code maintenable, extensible, bien structur√©  
‚úÖ **UI/UX professionnelle** : Interface moderne, responsive, intuitive  
‚úÖ **Gestion de donn√©es** : ETL, qualit√©, visualisations interactives  
‚úÖ **Bonnes pratiques** : S√©curit√©, performance, logging, tests  
‚úÖ **D√©ploiement** : Docker, cloud-ready, CI/CD  
‚úÖ **Documentation** : README complet, code comment√©, guides utilisateur  

**Cette application constitue un portfolio technique impressionnant pour tout poste en Data Science, d√©veloppement d'applications de sant√©, ou ing√©nierie logicielle !**